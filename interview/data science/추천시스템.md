# 추천시스템

- 성능 평가를 위한 지표

  - Precision

    선택된 아이템들 중 몇개의 아이템이 연관된 아이템들인가
    $$
    P = \frac{N_{rs}}{N_s}
    $$
    Precision은 연관된 아이템을 사용자가 찾는데에 도움을 준다

  - Recall

    연관된 아이템들 중 몇개의 아이템들이 선택되었는가
    $$
    R = \frac{N_{rs}}{N_r}
    $$
    Recall은 사용자가 연관된 아이템을 놓치지 않게 하고싶을 때에 도움은 준다

    두가지 모두를 사용하는 메트릭을 사용하려면 F-measure를 사용한다

  - Recall@K

    추천된 상위 K개의 아이템들 중 연관된 아이템이 몇개인가?

    결과적으로 Precision@K과 Recall@K은 같은 메트릭이다.

    이 메트릭은 많은 경우, 여러번의 실험 중 K개의 아이템 중 사용자가 선택한 아이템이 있다면 1 아니면 0으로 계산해

    총 평가 횟수 중 맞춘 갯수의 Percentage를 구하는 방법으로 대체한다. 

    예를 들어 10번의 실험 중 사용자가 선택한 아이템이 추천시스템이 예측한 아이템의 상위K개에 속한 경우가 3번 있다면 

    P@K는 0.3이 되는 것이다. 이는 결국 Online 실험에서의 CTR(Click Through Rate)과 같은 메트릭이다.

    Click Through Rate이란 보통 광고에서 광고의 노출수 분의 광고의 클릭수를 의미한다.

- Explicit Datasets, Implicit Datasets

  1. Explicit Datasets

     추천시스템을 만든다고 할 때 가장 먼저 떠오르는 데이터는 사용자의 평점 기록일 것이다. Movielens Data가 있다. (실제로 watcha는 점수형태로 Netflix는 좋아요,싫어요로 수집한다) 유저가 자신의 선호도를 직점(Explicit) 표현한 Data를 Explicit Data라고 칭한다.

     유용성은 좋지만 데이터를 얻기 힘들다

  2. Implicit Datasets

     유저가 간점적으로 선호, 취향을 나타내는 데이터를 의미한다. 검색기록, 방문페이지, 구매 내역, 심지어 마우스 움직임등을 이용하는 것이다.

     염두할 점이 조금 있다

     1. 부정적인 피드백이 없다
     2. 애초에 잡음이 많다
     3. 수치는 신뢰도를 의미한다

- Matrix Factorization

  - 명시적 프로필을 만들지 않고 이전 구매 기록이나 제품 평가 기록 등 과거 사용자 행동에만 의존해서 시스템을 구성한다. 이 방식은 유저-아이템 간의 상관관계를 찾아내는 것이 주 목적이라고 할 수 있다.
  - 협업 필터링은 **Domain-free** 즉, 특별히 이 분야에 대한 지식이 필요하지 않다는 장점을 가진다. 반면 새로운 사용자와 아이템을 다루기에 부적합하다는 **Cold Start Problem**이라는 한계가 있다

- knn

  - 장점
    - 간단하고 직관적인 접근 방식 때문에 구현 및 디버그가 쉽다
    - 특정 Item을 추천하는 이유를 정당화하기 쉽고 Item 기반 방법의 해석 가능성이 두드러집니다
    - 추천 리스트에 새로운 item, user가 추가되도 상대적으로 안정적
  - 단점
    - User 기반 방법의 시간, 속도, 메모리가 많이 필요
    - 희소성 때문에 제한된 범위가 있다

- Collaborative Filtering

  - 협업필터링이라고도 한다. 많은 유저들로부터 모은 정보들을 기반으로 하여 스스로 예측하는 기술
  - 유저 베이스, 아이템 베이스 두가지로 크게 나눈다

- Cold start

  - 데이터가 충분치 않은 상태이다
  - 해결법은 그냥 이거 다시 읽어라 [참고자료](https://techblog-history-younghunjo1.tistory.com/166)

